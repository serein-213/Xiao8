# Copyright (c) 2024 Alibaba Inc (authors: Xiang Lyu, Zhihao Du)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import regex
chinese_char_pattern = re.compile(r'[\u4e00-\u9fff]+')
bracket_patterns = [re.compile(r'\(.*?\)'),
                   re.compile('ï¼ˆ.*?ï¼‰')]

# whether contain chinese character
def contains_chinese(text):
    return bool(chinese_char_pattern.search(text))


# replace special symbol
def replace_corner_mark(text):
    text = text.replace('Â²', 'å¹³æ–¹')
    text = text.replace('Â³', 'ç«‹æ–¹')
    return text

def estimate_speech_time(text, unit_duration=0.2):
    # ä¸­æ–‡æ±‰å­—èŒƒå›´
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    chinese_units = len(chinese_chars) * 1.5

    # æ—¥æ–‡å‡åèŒƒå›´ï¼ˆå¹³å‡å 3040â€“309Fï¼Œç‰‡å‡å 30A0â€“30FFï¼‰
    japanese_kana = re.findall(r'[\u3040-\u30FF]', text)
    japanese_units = len(japanese_kana) * 1.0

    # è‹±æ–‡å•è¯ï¼ˆè¿ç»­çš„ a-z æˆ– A-Zï¼‰
    english_words = re.findall(r'\b[a-zA-Z]+\b', text)
    english_units = len(english_words) * 1.5

    total_units = chinese_units + japanese_units + english_units
    estimated_seconds = total_units * unit_duration

    return estimated_seconds

# remove meaningless symbol
def remove_bracket(text):
    for p in bracket_patterns:
        text = p.sub('', text)
    text = text.replace('ã€', '').replace('ã€‘', '')
    text = text.replace('ã€Š', '').replace('ã€‹', '')
    text = text.replace('`', '').replace('`', '')
    text = text.replace("â€”â€”", " ")
    text = text.replace("ï¼ˆ", "").replace("ï¼‰", "").replace("(", "").replace(")", "")
    return text


# spell Arabic numerals
def spell_out_number(text: str, inflect_parser):
    new_text = []
    st = None
    for i, c in enumerate(text):
        if not c.isdigit():
            if st is not None:
                num_str = inflect_parser.number_to_words(text[st: i])
                new_text.append(num_str)
                st = None
            new_text.append(c)
        else:
            if st is None:
                st = i
    if st is not None and st < len(text):
        num_str = inflect_parser.number_to_words(text[st:])
        new_text.append(num_str)
    return ''.join(new_text)


# split paragrah logicï¼š
# 1. per sentence max len token_max_n, min len token_min_n, merge if last sentence len less than merge_len
# 2. cal sentence len according to lang
# 3. split sentence according to punctuation
# 4. è¿”å›ï¼ˆè¦å¤„ç†çš„æ–‡æœ¬ï¼Œå‰©ä½™bufferï¼‰
def split_paragraph(text: str, force_process=False, lang="zh", token_min_n=2.5, comma_split=True):
    def calc_utt_length(_text: str):
        return estimate_speech_time(_text)

    if lang == "zh":
        pounc = ['ã€‚', 'ï¼Ÿ', 'ï¼', 'ï¼›', 'ï¼š', 'ã€', '.', '?', '!', ';']
    else:
        pounc = ['.', '?', '!', ';', ':']
    if comma_split:
        pounc.extend(['ï¼Œ', ','])

    st = 0
    utts = []
    for i, c in enumerate(text):
        if c in pounc:
            if len(text[st: i]) > 0:
                utts.append(text[st: i+1])
            if i + 1 < len(text) and text[i + 1] in ['"', 'â€']:
                tmp = utts.pop(-1)
                utts.append(tmp + text[i + 1])
                st = i + 2
            else:
                st = i + 1

    if len(utts) == 0: # æ²¡æœ‰ä¸€ä¸ªæ ‡ç‚¹
        if force_process:
            return text, ""
        else:
            return "", text
    elif calc_utt_length(utts[-1]) > token_min_n: #å¦‚æœæœ€åä¸€ä¸ªutté•¿åº¦è¾¾æ ‡
        # print(f"ğŸ’¼åç«¯è¿›è¡Œåˆ‡å‰²ï¼š|| {''.join(utts)} || {text[st:]}")
        return ''.join(utts), text[st:]
    elif len(utts)==1: #å¦‚æœé•¿åº¦ä¸è¾¾æ ‡ï¼Œä½†æ²¡æœ‰å…¶ä»–utt
        if force_process:
            return text, ""
        else:
            return "", text
    else:
        # print(f"ğŸ’¼åç«¯è¿›è¡Œåˆ‡å‰²ï¼š|| {''.join(utts[:-1])} || {utts[-1] + text[st:]}")
        return ''.join(utts[:-1]), utts[-1] + text[st:]

# remove blank between chinese character
def replace_blank(text: str):
    out_str = []
    for i, c in enumerate(text):
        if c == " ":
            if ((text[i + 1].isascii() and text[i + 1] != " ") and
                    (text[i - 1].isascii() and text[i - 1] != " ")):
                out_str.append(c)
        else:
            out_str.append(c)
    return "".join(out_str)


def is_only_punctuation(text):
    # Regular expression: Match strings that consist only of punctuation marks or are empty.
    punctuation_pattern = r'^[\p{P}\p{S}]*$'
    return bool(regex.fullmatch(punctuation_pattern, text))